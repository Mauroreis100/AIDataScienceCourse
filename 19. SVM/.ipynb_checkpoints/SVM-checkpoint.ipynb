{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a018bd7e-4905-4655-8aa4-59ade157ee22",
   "metadata": {},
   "source": [
    "# The purpose of this Sprint\n",
    "Understand SVM through scratch\n",
    "Touch a method different from the linear model\n",
    "How to learn\n",
    "After implementing SVM with scratch, we will train and verify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0dd73d-421c-4797-8852-ca8748ad7840",
   "metadata": {},
   "source": [
    "We will create a class of support vector machine (SVM, support vector machine) for classification by scratch. We will implement the algorithm using only the minimum library such as NumPy.\n",
    "\n",
    "There are soft margin SVMs that allow classification errors during learning and hard margin SVMs that do not, but here we will deal with hard margin SVMs that are simple to implement.\n",
    "\n",
    "The template is prepared below. Add some code to this ScratchSVMClassifier class.\n",
    "\n",
    "PrototypeWe will create a class of support vector machine (SVM, support vector machine) for classification by scratch. We will implement the algorithm using only the minimum library such as NumPy.\n",
    "\n",
    "There are soft margin SVMs that allow classification errors during learning and hard margin SVMs that do not, but here we will deal with hard margin SVMs that are simple to implement.\n",
    "\n",
    "The template is prepared below. Add some code to this ScratchSVMClassifier class.\n",
    "\n",
    "Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0a7abe-8574-42e1-9ad2-0939b1faa8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSVMClassifier():\n",
    "    \"\"\"\n",
    "    Scratch implementation of SVM classifier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      Number of iterations\n",
    "    lr : float\n",
    "      Learning rate\n",
    "    kernel : str\n",
    "      Kernel type. Linear kernel (linear) or polynomial kernel (polly)\n",
    "    threshold : float\n",
    "      Threshold for choosing a support vector\n",
    "    verbose : bool\n",
    "      True to output the learning process\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.n_support_vectors : int\n",
    "      Number of support vectors\n",
    "    self.index_support_vectors : The following form of ndarray, shape (n_support_vectors,)\n",
    "      Support vector index\n",
    "    self.X_sv :  The following forms of ndarray, shape (n_support_vectors, n_features)\n",
    "      Support vector features\n",
    "    self.lam_sv :  The following forms of ndarray, shape (n_support_vectors, 1)\n",
    "      Support vector undetermined multiplier\n",
    "    self.y_sv :  The following forms of ndarray, shape (n_support_vectors, 1)\n",
    "      Support vector label\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, kernel='linear', threshold=1e-5, verbose=False):\n",
    "        # Record hyperparameters as attributes\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel = kernel\n",
    "        self.threshold = threshold\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Learn the SVM classifier. If verification data is input, the accuracy for it is also calculated for each iteration.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : of the following form. ndarray, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        y : The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        X_val : of the following form. ndarray, shape (n_samples, n_features)\n",
    "            Features of verification data\n",
    "        y_val : The following form of ndarray, shape (n_samples,)\n",
    "            Correct value of verification data\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            #Output the learning process when #verbose is set to True\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate the label using the SVM classifier.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : of the following form. ndarray, shape (n_samples, n_features)\n",
    "            sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            The following form of ndarray, shape (n_samples, 1)\n",
    "            Estimated result by SVM classifier\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b7ac6-06ae-4d55-8055-2b9b839db6bf",
   "metadata": {},
   "source": [
    "【problem 1】Lagrange’s steepest descent by the undetermined multiplier method\n",
    "Lagrange’s undetermined multiplier method is used for SVM learning. Prepare Lagrange multiplier $\\lambda$ for the number of samples and update it by the following formula. Implement the method that performs this calculation in the ScratchSVMClassifier class.\n",
    "\n",
    "lambda​ ​n​ ​e​ ​LOL​ ​I​ ​=​ ​lambda​ ​I​ ​+​ ​alpha​ ​(1-n​ ​∑​ ​J​ ​=​ ​1​ ​lambda​ ​J​ ​Y​ ​I​ ​Y​ ​J​ ​K​ ​(an unknown​ ​I,​ ​an unknown​ ​J))λinew=λi+α(1−∑j=1nλjyiyjK(xi,xj))\n",
    "\n",
    "Where $k(x_i, x_j)$ is a kernel function. For a linear kernel: Let’s leave this part as an independent method so that it can correspond to other kernel functions.\n",
    "\n",
    "K​ ​(an unknown​ ​I,​ ​an unknown​ ​J)​ ​=​ ​an unknown​ ​t​ ​I​ ​an unknown​ ​JK(xi,xj)=xiTxj\n",
    "\n",
    "As a condition, $\\lambda_i >= 0$ must be satisfied for each update. If not, set $\\lambda_i = 0$.\n",
    "\n",
    "$i, j$: sample index\n",
    "\n",
    "$\\lambda_i^{new}$: Lagrange multiplier for i-th sample after update\n",
    "\n",
    "$\\lambda_i$: Lagrange multiplier of i-th sample before update\n",
    "\n",
    "$\\alpha$: learning rate\n",
    "\n",
    "$\\lambda_j$: Lagrange multiplier for the jth sample\n",
    "\n",
    "$y_i$: Label for i-th sample\n",
    "\n",
    "$y_j$: Label for the jth sample\n",
    "\n",
    "$x_i$: Feature vector of i-th sample\n",
    "\n",
    "$x_j$: Feature vector of jth sample\n",
    "\n",
    "You will be calculating the relationship for one sample with all the samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc4456-dca4-426a-b465-cf37467642d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
