{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8a9271-6e74-4205-a8fb-22ef54a45ea3",
   "metadata": {},
   "source": [
    "# Ensemble learning\n",
    "We will implement scratch implementation of three types of ensemble learning. Then check each effect on a smaller dataset.\n",
    "\n",
    "* Blending\n",
    "* Bagging\n",
    "* Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e105c265-7ce3-466e-b721-455451177a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c2a05d-854f-4b39-bdcf-214cc53a119f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  OpenPorchSF  \\\n",
       "0          2003       196.0         706  ...           0           61   \n",
       "1          1976         0.0         978  ...         298            0   \n",
       "2          2002       162.0         486  ...           0           42   \n",
       "3          1970         0.0         216  ...           0           35   \n",
       "4          2000       350.0         655  ...         192           84   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       2    2008   \n",
       "1              0          0            0         0        0       5    2007   \n",
       "2              0          0            0         0        0       9    2008   \n",
       "3            272          0            0         0        0       2    2006   \n",
       "4              0          0            0         0        0      12    2008   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train.csv').select_dtypes(include='number')\n",
    "data.isnull().sum()\n",
    "data = data.fillna(data.mean())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbc06b6-c912-45da-a6f2-ccdf6b991a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-(1460, 37), y-(1460,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['SalePrice'],axis=1).values\n",
    "y = data['SalePrice'].values\n",
    "X = np.log1p(X)\n",
    "y = np.log1p(y)\n",
    "print('X-{}, y-{}'.format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f09ed-341a-4a95-89db-9a5040dcc160",
   "metadata": {},
   "source": [
    "# Problem 1] Blending scratch mounting\n",
    "Show at least three​ ​examples of scratch implementation of blending that are more accurate than a single model. Higher accuracy means less mean squared error (MSE) on the validation data.\n",
    "\n",
    "# What is blending?\n",
    "Blending is a method of independently training N diverse models, weighting the estimation results, and then adding them together. The simplest is to take the average. Various models are created by changing the following conditions.\n",
    "\n",
    "Techniques (eg linear regression, SVM, decision tree, neural network, etc.)\n",
    "Hyperparameters (eg SVM kernel type, initial weights, etc.)\n",
    "How to preprocess input data (eg standardization, logarithmic transformation, PCA, etc.)\n",
    "The important thing is that each model is very different.\n",
    "\n",
    "Blending in regression problems is so simple that it is not provided in scikit-learn.\n",
    "\n",
    "《 Supplemental information\n",
    "》\n",
    "\n",
    "In the case of a classification problem, a majority vote will be taken. Because it is more complicated than regression problems, scikit-learn provides a Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce833ed0-85b3-469e-a381-91d6b33b8726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b82c523-83e7-47cb-8edd-698d084b7022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "Blend:0.024\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions = list()\n",
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions.append(model.predict(X_test))\n",
    "    \n",
    "predictions_ndarray = np.array(predictions)\n",
    "blend = np.mean(predictions_ndarray,axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print(mean_squared_error(y_test,blend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82dad69e-5fd4-4da8-b1de-7eaa51ca8d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "Blend:0.023\n"
     ]
    }
   ],
   "source": [
    "svr_model1 = SVR(C=1)\n",
    "svr_model2 = SVR(C=5)\n",
    "svr_model3 = SVR(C=10)\n",
    "svr_model1.fit(X_train,y_train)\n",
    "svr_model2.fit(X_train,y_train)\n",
    "svr_model3.fit(X_train,y_train)\n",
    "svr_pred1 = svr_model1.predict(X_test)\n",
    "svr_pred2 = svr_model2.predict(X_test)\n",
    "svr_pred3 = svr_model2.predict(X_test)  \n",
    "svr_blend = np.mean([svr_pred1,svr_pred2,svr_pred3],axis=0)\n",
    "print('MSE')\n",
    "print('Blend:{:.3f}'.format(mean_squared_error(y_test,svr_blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c4ce13-79ee-46bf-968c-bd339b36a4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "Blend:0.024\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_trans = std_scaler.transform(X_train)\n",
    "X_test_trans = std_scaler.transform(X_test)\n",
    "\n",
    "models2 = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions2 = list()\n",
    "for model in models2:\n",
    "    model.fit(X_train_trans,y_train)\n",
    "    predictions2.append(model.predict(X_test_trans))\n",
    "    \n",
    "predictions_ndarray2 = np.array(predictions)\n",
    "blend2 = np.mean(predictions_ndarray2,axis=0)\n",
    "print('MSE')\n",
    "print((mean_squared_error(y_test,blend2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cb888-c0ea-4b26-98d0-b5a3b77a3d8d",
   "metadata": {},
   "source": [
    "# 4.Bagging\n",
    "# [Problem 2] Scratch mounting of bagging\n",
    "Please show at least one​ ​example where you scratch-implement the bagging and it is more accurate than a single model.\n",
    "\n",
    "# What is bagging?\n",
    "Bagging is a way to diversify how to select input data. N types of subsets (bootstrap samples) are created by randomly extracting from the training data after allowing duplication. N models are trained by them and the estimation results are averaged. Unlike blending, each weight does not change.\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "The part that averages the estimation results is implemented in the same way as blending.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "016c7271-973c-4149-93e3-f2f37da88d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train_bag.shape,y_test_bag.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc1f72e-41da-48db-9a6b-e0b87949b2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average of bagging pred:[12.25781018 12.00773981 11.56490218 11.01704575 11.94186951 12.60472669\n",
      " 12.59121682 11.86406303 12.27052756 12.41231464 12.0939682  11.03249063\n",
      " 12.18649386 12.82128078 12.32959948 11.64537706 11.62101697 11.72522247\n",
      " 12.28233403 11.77422308 11.66586087 11.82571449 12.42377148 12.65000953\n",
      " 11.4749905  12.20523297 11.72834793 12.17416771 12.86618536 11.87711754\n",
      " 11.73072584 11.68659899 11.65633567 11.53485066 11.90581371 12.73189308\n",
      " 11.77319291 11.30574824 12.57546139 11.67492642 11.89372723 11.93295879\n",
      " 11.55077765 11.74298774 12.14631247 12.09052153 11.74710802 12.06724842\n",
      " 12.40174075 12.37049595 11.61414461 12.65479343 11.50253555 12.34734819\n",
      " 12.25089831 11.55525153 11.67917674 12.03161852 11.73023127 12.1246947\n",
      " 12.05537367 12.55936264 11.48497146 11.57012425 12.04109569 11.78683765\n",
      " 11.75998572 12.36580131 12.07654313 11.93577139 12.01896958 11.49884952\n",
      " 12.64776829 11.95045468 12.01314801 12.26227902 12.04329547 11.86340477\n",
      " 12.92208333 12.231429   12.2218487  11.75390128 11.79758841 12.00855168\n",
      " 12.2044458  12.02820085 11.99980867 12.02568851 12.14031919 12.09982482\n",
      " 12.20926098 11.98374621 11.58035304 11.49854593 11.77168392 11.78590205\n",
      " 11.67651947 11.81202738 11.95026297 11.88906072 11.98585921 11.81101929\n",
      " 11.65284482 11.64858042 11.79048556 12.14972015 12.07796969 12.17464549\n",
      " 11.92171686 12.65617751 11.86217674 12.10094728 11.90928349 12.1900358\n",
      " 12.38660575 12.04175793 12.33100862 11.76253113 12.05778526 12.50896672\n",
      " 11.81249862 12.28891716 12.74241422 11.95535723 12.08302274 12.14328756\n",
      " 12.63302218 11.64641506 12.22847787 12.26244683 12.51616082 11.41171568\n",
      " 11.75950486 11.79975634 11.46961195 12.23350378 12.99362144 12.68279786\n",
      " 12.38678206 11.84962957 11.76234107 12.54425055 12.14410725 12.18017725\n",
      " 11.53200446 12.12776861 11.49762479 12.14239053 12.31327595 11.60348324\n",
      " 12.12636599 12.02254067 11.69406535 12.11512468 12.16091405 12.58597647\n",
      " 11.20881159 11.83875928 11.33126345 11.81556985 10.93952586 11.51336094\n",
      " 11.90795891 11.88615261 11.59471811 11.79566914 11.98063652 11.83334174\n",
      " 11.89244882 11.56269796 12.35661599 11.87725353 12.31573002 12.51213745\n",
      " 12.21220532 11.81282669 12.22983649 12.19986341 11.82105823 12.0558039\n",
      " 11.8343862  12.06805951 11.92785474 11.89133242 12.55767453 11.84760809\n",
      " 12.5735829  12.58176614 12.05836336 11.72081253 11.53627764 11.93276551\n",
      " 11.47359134 12.17529414 11.78446624 12.49540956 12.33434989 11.95270052\n",
      " 11.88356441 11.03802792 12.20145392 12.35417099 12.10713942 12.0819618\n",
      " 12.43058494 11.70484107 12.1352952  12.62632821 12.41675293 12.34499726\n",
      " 12.1980879  11.64350693 11.97478786 11.69801762 12.57630428 12.44839643\n",
      " 11.70813187 11.37884673 12.25849631 11.14306648 12.96846366 11.69281289\n",
      " 11.93344705 12.21364068 11.6743006  11.72987818 12.17918392 12.0550451\n",
      " 11.94046769 12.02430028 11.69562664 12.09797776 11.47499846 11.73325161\n",
      " 12.64600432 11.67891512 12.59817909 11.66545513 11.79075479 12.62023138\n",
      " 12.72303774 12.06302374 11.8602322  11.87322199 11.82723683 11.68963334\n",
      " 11.96200222 11.8908257  11.98949411 11.97644006 11.63564484 11.58921417\n",
      " 12.09134308 12.08935    11.6225595  11.66887091 12.14538924 11.2683327\n",
      " 12.62541987 11.75358959 12.25075163 12.15641717 12.27755744 12.06339638\n",
      " 11.58558014 12.23770599 11.77528161 12.13616113 11.89242056 11.4934439\n",
      " 12.09590801 12.11092546 11.38813463 11.66018836 12.11537418 11.41598007\n",
      " 11.66630664 11.81608939 11.95899572 11.82833539 11.8130794  11.82417407\n",
      " 11.77505609 11.93245587 12.37112628 12.41784365 11.70926131 11.34078978\n",
      " 12.38449439 11.48194682 11.37364782 12.51356676]\n",
      "average of bagging mse:0.022\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "class BaggingScratch():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.predictions = list()\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        for model in models:\n",
    "            model.fit(X,y)\n",
    "    def predict(self,X):\n",
    "        predictions = list()\n",
    "        for model in self.models:\n",
    "            prediction = model.predict(X)\n",
    "            predictions.append(prediction)\n",
    "        self.predictions = np.mean(np.array(predictions),axis=0)\n",
    "        return self.predictions\n",
    "    def mse(self, y):\n",
    "        mse = (mean_squared_error(y,self.predictions))\n",
    "        return mse\n",
    "    \n",
    "bag = BaggingScratch(models)\n",
    "bag.fit(X_train,y_train)\n",
    "print(\"average of bagging pred:{}\".format(bag.predict(X_test)))\n",
    "print(\"average of bagging mse:{:.3f}\".format(bag.mse(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b017c-934d-4a9b-b41e-efe33a6c8690",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "# [Problem 3] Stacking scratch mounting\n",
    "Please show at least one​ ​example where stacking is scratch-implemented and more accurate than a single model.\n",
    "\n",
    "What is stacking?\n",
    "The stacking procedure is as follows. Stacking is possible if there is at least stage 0 and stage 1, so implement it. First of all, we will start to the extent ​K​ ​0​ ​=​ ​3​,​ ​M​ ​0​ ​=​ ​2K0=3,M0=2.\n",
    "\n",
    "《When learning》\n",
    "\n",
    "(stage 00 ）\n",
    "\n",
    "Training data K​ ​0K0Divide into pieces.\n",
    "With(K​ ​0​ ​−​ ​1)(K0−1)Training data collectively, the rest 11for estimation, we can make K​ ​0K0 estimation.\n",
    "We haveK​ ​0K0Prepare individual pieces and learn using different training data.\n",
    "For each trained model, the remaining 11 unused estimation data is input to obtain an estimate. (This is called blended data.)\n",
    "We also prepare K​ ​0K0 instances of different models and do the same thing. If there are M​ ​0M0 models, M​ ​0M0 blended data will be obtained.\n",
    "(stage nn ）\n",
    "\n",
    "The blended data of stage n​ ​−​ ​1n−1 is considered as the training data with M​ ​n​ ​−​ ​1Mn−1Think of it as training data with dimensional features, K​ ​nKn pieces. The same applies below.\n",
    "(stage NN) *Last stage\n",
    "\n",
    "stage N​ ​−​ ​1N−1of M​ ​N​ ​−​ ​1MN−1Blend data M​ ​N​ ​−​ ​1MN−1One type of model is trained as an input of dimensional features. This is the model for the final estimation.\n",
    "《Estimated time》\n",
    "\n",
    "(stage 00 ）\n",
    "\n",
    "Test data K​ ​0​ ​x​ ​M​ ​0K0×M0Fill in the trained models and K​ ​0​ ​x​ ​M​ ​0K0×M0Get an estimate. this K​ ​0K0Calculate the average value on the axis of M​ ​0M0Obtain data with dimensional features. (Called a blend test)\n",
    "(stage nn ）\n",
    "\n",
    "The blended data of stage n​ ​−​ ​1n−1The blend test obtained in K​ ​n​ ​×​ ​M​ ​nKn×MnFill in the trained models and K​ ​n​ ​×​ ​M​ ​nKn×MnGet an estimate. this K​ ​nKnCalculate the average value on the axis of M​ ​0M0Obtain data with dimensional features. (Called a blend test)\n",
    "(stage NN) *Last stage\n",
    "\n",
    "stage N​ ​−​ ​1N−1Input the blend test obtained in step 2 into the trained model to obtain an estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ffbeab6-e8f6-48ef-8ca3-6c03dd033018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    X, y = datasets.make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset()\n",
    "X_train_full, X_test_1, y_train_full, y_test_1 = train_test_split(X,y,test_size=0.5,random_state=1)\n",
    "X_train_1, X_val, y_train_1, y_val = train_test_split(X_train_full,y_train_full,test_size=0.2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8645b140-4582-422a-8bba-9290988aa2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr',LinearRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeRegressor()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "def fit_ensemble(models, X_train_1, X_val, y_train_1, y_val):\n",
    "    meta_X = list()\n",
    "    for name,model in models:\n",
    "        model.fit(X_train_1, y_train_1)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    blender = LinearRegression()\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "def pred_ensemble(models, blender, X_test_1):\n",
    "    meta_X = list()\n",
    "    for name,model in models:\n",
    "        y_pred = model.predict(X_test_1)\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    return blender.predict(meta_X)\n",
    "\n",
    "models = get_models()\n",
    "blender = fit_ensemble(models, X_train_1, X_val, y_train_1, y_val)\n",
    "y_pred = pred_ensemble(models, blender, X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5e85aea-683f-4631-9222-1fec3f3df2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values used\n",
      "Train:(4000, 20) Val:(1000, 20) Test:(5000, 20)\n",
      "Accuracy score\n",
      "------------------\n",
      "Blended ensemble:0.023\n",
      "Logistic regression:0.110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train:{} Val:{} Test:{}\".format(X_train_1.shape, X_val.shape, X_test_1.shape))\n",
    "print(\"Accuracy score\")\n",
    "print(\"------------------\")\n",
    "print(\"Blended ensemble:{:.3f}\".format(mean_squared_error(y_test_1,y_pred)))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_1, y_train_1)\n",
    "y_pred1= model.predict(X_test_1)\n",
    "print(\"Logistic regression:{:.3f}\".format(mean_squared_error(y_test_1,y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f180e-a7f7-469d-9c93-a7f88e5143db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06e0fa-ed59-4184-9e07-d9e41c457801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5071cc-d864-420e-8c13-68903fc31aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b6788-ba89-46d9-813f-0889de9d0db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4205740-c2b2-4a44-b513-f74828101f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
