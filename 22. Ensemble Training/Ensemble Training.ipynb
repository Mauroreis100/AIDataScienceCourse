{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8a9271-6e74-4205-a8fb-22ef54a45ea3",
   "metadata": {},
   "source": [
    "# Ensemble learning\n",
    "We will implement scratch implementation of three types of ensemble learning. Then check each effect on a smaller dataset.\n",
    "\n",
    "* Blending\n",
    "* Bagging\n",
    "* Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e105c265-7ce3-466e-b721-455451177a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c2a05d-854f-4b39-bdcf-214cc53a119f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  OpenPorchSF  \\\n",
       "0          2003       196.0         706  ...           0           61   \n",
       "1          1976         0.0         978  ...         298            0   \n",
       "2          2002       162.0         486  ...           0           42   \n",
       "3          1970         0.0         216  ...           0           35   \n",
       "4          2000       350.0         655  ...         192           84   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       2    2008   \n",
       "1              0          0            0         0        0       5    2007   \n",
       "2              0          0            0         0        0       9    2008   \n",
       "3            272          0            0         0        0       2    2006   \n",
       "4              0          0            0         0        0      12    2008   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train.csv').select_dtypes(include='number')\n",
    "data.isnull().sum()\n",
    "data = data.fillna(data.mean())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbc06b6-c912-45da-a6f2-ccdf6b991a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-(1460, 37), y-(1460,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['SalePrice'],axis=1).values\n",
    "y = data['SalePrice'].values\n",
    "X = np.log1p(X)\n",
    "y = np.log1p(y)\n",
    "print('X-{}, y-{}'.format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f09ed-341a-4a95-89db-9a5040dcc160",
   "metadata": {},
   "source": [
    "# Problem 1] Blending scratch mounting\n",
    "Show at least three​ ​examples of scratch implementation of blending that are more accurate than a single model. Higher accuracy means less mean squared error (MSE) on the validation data.\n",
    "\n",
    "# What is blending?\n",
    "Blending is a method of independently training N diverse models, weighting the estimation results, and then adding them together. The simplest is to take the average. Various models are created by changing the following conditions.\n",
    "\n",
    "Techniques (eg linear regression, SVM, decision tree, neural network, etc.)\n",
    "Hyperparameters (eg SVM kernel type, initial weights, etc.)\n",
    "How to preprocess input data (eg standardization, logarithmic transformation, PCA, etc.)\n",
    "The important thing is that each model is very different.\n",
    "\n",
    "Blending in regression problems is so simple that it is not provided in scikit-learn.\n",
    "\n",
    "《 Supplemental information\n",
    "》\n",
    "\n",
    "In the case of a classification problem, a majority vote will be taken. Because it is more complicated than regression problems, scikit-learn provides a Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce833ed0-85b3-469e-a381-91d6b33b8726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b82c523-83e7-47cb-8edd-698d084b7022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "0.021989903025349554\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions = list()\n",
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions.append(model.predict(X_test))\n",
    "    \n",
    "predictions_ndarray = np.array(predictions)\n",
    "blend = np.mean(predictions_ndarray,axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print(mean_squared_error(y_test,blend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dad69e-5fd4-4da8-b1de-7eaa51ca8d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "Blend:0.023\n"
     ]
    }
   ],
   "source": [
    "svr_model1 = SVR(C=1)\n",
    "svr_model2 = SVR(C=5)\n",
    "svr_model3 = SVR(C=10)\n",
    "svr_model1.fit(X_train,y_train)\n",
    "svr_model2.fit(X_train,y_train)\n",
    "svr_model3.fit(X_train,y_train)\n",
    "svr_pred1 = svr_model1.predict(X_test)\n",
    "svr_pred2 = svr_model2.predict(X_test)\n",
    "svr_pred3 = svr_model2.predict(X_test)  \n",
    "svr_blend = np.mean([svr_pred1,svr_pred2,svr_pred3],axis=0)\n",
    "print('MSE')\n",
    "print('Blend:{:.3f}'.format(mean_squared_error(y_test,svr_blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c4ce13-79ee-46bf-968c-bd339b36a4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "0.021989903025349554\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_trans = std_scaler.transform(X_train)\n",
    "X_test_trans = std_scaler.transform(X_test)\n",
    "\n",
    "models2 = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions2 = list()\n",
    "for model in models2:\n",
    "    model.fit(X_train_trans,y_train)\n",
    "    predictions2.append(model.predict(X_test_trans))\n",
    "    \n",
    "predictions_ndarray2 = np.array(predictions)\n",
    "blend2 = np.mean(predictions_ndarray2,axis=0)\n",
    "print('MSE')\n",
    "print((mean_squared_error(y_test,blend2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cb888-c0ea-4b26-98d0-b5a3b77a3d8d",
   "metadata": {},
   "source": [
    "# 4.Bagging\n",
    "# [Problem 2] Scratch mounting of bagging\n",
    "Please show at least one​ ​example where you scratch-implement the bagging and it is more accurate than a single model.\n",
    "\n",
    "# What is bagging?\n",
    "Bagging is a way to diversify how to select input data. N types of subsets (bootstrap samples) are created by randomly extracting from the training data after allowing duplication. N models are trained by them and the estimation results are averaged. Unlike blending, each weight does not change.\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "The part that averages the estimation results is implemented in the same way as blending.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "016c7271-973c-4149-93e3-f2f37da88d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train_bag.shape,y_test_bag.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc1f72e-41da-48db-9a6b-e0b87949b2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average of bagging pred:[12.25781018 11.99545486 11.56490218 11.01704575 11.89735932 12.60472669\n",
      " 12.59121682 11.86406303 12.27052756 12.36113397 12.0939682  11.08387363\n",
      " 12.18649386 12.82128078 12.32959948 11.60539099 11.61961935 11.72522247\n",
      " 12.32655348 11.74982214 11.65550567 11.71891534 12.44081091 12.65000953\n",
      " 11.4749905  12.20523297 11.72834793 12.16725904 12.86494783 11.86085426\n",
      " 11.73072584 11.69092576 11.65772745 11.53485066 11.90581371 12.73189308\n",
      " 11.77319291 11.32333622 12.57546139 11.67098164 11.89106665 11.92868525\n",
      " 11.55077765 11.74554201 12.13173827 12.09052153 11.75582306 12.00658681\n",
      " 12.41677083 12.387204   11.61414461 12.74536037 11.50486925 12.3525508\n",
      " 12.2601907  11.55525153 11.66513099 12.03161852 11.74564378 12.13721745\n",
      " 12.05648355 12.53183387 11.48497146 11.57012425 12.04109569 11.78683765\n",
      " 11.74946287 12.36580131 12.07654313 11.93577139 12.01896958 11.49884952\n",
      " 12.65849332 11.94814788 12.01314801 12.26227902 12.07852157 11.86209502\n",
      " 12.92208333 12.231429   12.18280714 11.75390128 11.79758841 11.96404148\n",
      " 12.19222809 12.02886818 11.99980867 12.04381338 12.14218659 12.07272789\n",
      " 12.1932301  11.98374621 11.58035304 11.49854593 11.79144265 11.75484805\n",
      " 11.66549927 11.80236494 11.9508153  11.88906072 11.92360108 11.80841032\n",
      " 11.63764146 11.64858042 11.79048556 12.12334119 12.07796969 12.16563238\n",
      " 11.92171686 12.65617751 11.86217674 12.1260713  11.90928349 12.18312712\n",
      " 12.38660575 12.04313444 12.30864661 11.75944756 12.03873256 12.50896672\n",
      " 11.87475675 12.22269393 12.74241422 11.95535723 12.20320309 12.14753859\n",
      " 12.60499457 11.64641506 12.22847787 12.26323617 12.49906312 11.41141251\n",
      " 11.76197399 11.83854797 11.47063079 12.22225778 13.04064753 12.68279786\n",
      " 12.3851558  11.85316862 11.76234107 12.54425055 12.14054819 12.1630246\n",
      " 11.53496742 12.22071332 11.49762479 12.16087494 12.33775166 11.60348324\n",
      " 12.12902204 12.02254067 11.69002493 12.11512468 12.17955682 12.63505306\n",
      " 11.24559369 11.83875928 11.25809779 11.83128534 10.83409738 11.49062511\n",
      " 11.90795891 11.88615261 11.62666707 11.79329666 11.98063652 11.86075426\n",
      " 11.89244882 11.58543379 12.35661599 11.87206539 12.31573002 12.51066755\n",
      " 12.22329101 11.81543566 12.21781183 12.17304408 11.7293578  12.0558039\n",
      " 11.8343862  12.06805951 11.92785474 11.89133242 12.53327963 11.85026866\n",
      " 12.5735829  12.59249117 12.00259709 11.70744783 11.53627764 11.93276551\n",
      " 11.489222   12.24655159 11.77933798 12.50995396 12.33146388 11.94600829\n",
      " 11.90384482 11.03802792 12.21993043 12.35417099 12.10621478 12.08403982\n",
      " 12.46583316 11.72258911 12.14260578 12.61928926 12.40200476 12.34499726\n",
      " 12.20238901 11.63503197 11.97478786 11.69125611 12.5161836  12.44839643\n",
      " 11.72163508 11.37884673 12.17970052 11.13916403 13.03442898 11.69281289\n",
      " 11.93344705 12.20290044 11.68400841 11.72987818 12.17918392 12.05596463\n",
      " 11.94046769 12.02430028 11.67657401 12.09797776 11.57670461 11.79550974\n",
      " 12.63088827 11.67891512 12.59720014 11.66545513 11.80014501 12.61925243\n",
      " 12.74165361 12.06302374 11.8602322  11.87322199 11.82723683 11.68963334\n",
      " 11.91123397 11.93533587 11.98949411 11.97644006 11.63564484 11.58921417\n",
      " 12.09134308 12.08235329 11.60727627 11.66598492 12.17046359 11.2683327\n",
      " 12.62561781 11.75866171 12.25075163 12.15255465 12.27384959 12.06339638\n",
      " 11.58558014 12.23770599 11.81074152 12.12709153 11.91592498 11.49541045\n",
      " 12.12482482 12.09942005 11.38813463 11.64913052 12.05311605 11.40596943\n",
      " 11.66898401 11.80076114 11.95380759 11.89474759 11.82820696 11.82417407\n",
      " 11.77505609 11.9215823  12.37112628 12.41784365 11.71135554 11.35080043\n",
      " 12.33345399 11.48194682 11.39765627 12.50343792]\n",
      "average of bagging mse:0.022\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "class BaggingScratch():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.predictions = list()\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        for model in models:\n",
    "            model.fit(X,y)\n",
    "    def predict(self,X):\n",
    "        predictions = list()\n",
    "        for model in self.models:\n",
    "            prediction = model.predict(X)\n",
    "            predictions.append(prediction)\n",
    "        self.predictions = np.mean(np.array(predictions),axis=0)\n",
    "        return self.predictions\n",
    "    def mse(self, y):\n",
    "        mse = (mean_squared_error(y,self.predictions))\n",
    "        return mse\n",
    "    \n",
    "bag = BaggingScratch(models)\n",
    "bag.fit(X_train,y_train)\n",
    "print(\"average of bagging pred:{}\".format(bag.predict(X_test)))\n",
    "print(\"average of bagging mse:{:.3f}\".format(bag.mse(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b017c-934d-4a9b-b41e-efe33a6c8690",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "# [Problem 3] Stacking scratch mounting\n",
    "Please show at least one​ ​example where stacking is scratch-implemented and more accurate than a single model.\n",
    "\n",
    "What is stacking?\n",
    "The stacking procedure is as follows. Stacking is possible if there is at least stage 0 and stage 1, so implement it. First of all, we will start to the extent ​K​ ​0​ ​=​ ​3​,​ ​M​ ​0​ ​=​ ​2K0=3,M0=2.\n",
    "\n",
    "《When learning》\n",
    "\n",
    "(stage 00 ）\n",
    "\n",
    "Training data K​ ​0K0Divide into pieces.\n",
    "With(K​ ​0​ ​−​ ​1)(K0−1)Training data collectively, the rest 11for estimation, we can make K​ ​0K0 estimation.\n",
    "We haveK​ ​0K0Prepare individual pieces and learn using different training data.\n",
    "For each trained model, the remaining 11 unused estimation data is input to obtain an estimate. (This is called blended data.)\n",
    "We also prepare K​ ​0K0 instances of different models and do the same thing. If there are M​ ​0M0 models, M​ ​0M0 blended data will be obtained.\n",
    "(stage nn ）\n",
    "\n",
    "The blended data of stage n​ ​−​ ​1n−1 is considered as the training data with M​ ​n​ ​−​ ​1Mn−1Think of it as training data with dimensional features, K​ ​nKn pieces. The same applies below.\n",
    "(stage NN) *Last stage\n",
    "\n",
    "stage N​ ​−​ ​1N−1of M​ ​N​ ​−​ ​1MN−1Blend data M​ ​N​ ​−​ ​1MN−1One type of model is trained as an input of dimensional features. This is the model for the final estimation.\n",
    "《Estimated time》\n",
    "\n",
    "(stage 00 ）\n",
    "\n",
    "Test data K​ ​0​ ​x​ ​M​ ​0K0×M0Fill in the trained models and K​ ​0​ ​x​ ​M​ ​0K0×M0Get an estimate. this K​ ​0K0Calculate the average value on the axis of M​ ​0M0Obtain data with dimensional features. (Called a blend test)\n",
    "(stage nn ）\n",
    "\n",
    "The blended data of stage n​ ​−​ ​1n−1The blend test obtained in K​ ​n​ ​×​ ​M​ ​nKn×MnFill in the trained models and K​ ​n​ ​×​ ​M​ ​nKn×MnGet an estimate. this K​ ​nKnCalculate the average value on the axis of M​ ​0M0Obtain data with dimensional features. (Called a blend test)\n",
    "(stage NN) *Last stage\n",
    "\n",
    "stage N​ ​−​ ​1N−1Input the blend test obtained in step 2 into the trained model to obtain an estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ffbeab6-e8f6-48ef-8ca3-6c03dd033018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    X, y = datasets.make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset()\n",
    "X_train_full, X_test_1, y_train_full, y_test_1 = train_test_split(X,y,test_size=0.5,random_state=1)\n",
    "X_train_1, X_val, y_train_1, y_val = train_test_split(X_train_full,y_train_full,test_size=0.2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8645b140-4582-422a-8bba-9290988aa2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr',LinearRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeRegressor()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "def fit_ensemble(models, X_train_1, X_val, y_train_1, y_val):\n",
    "    meta_X = list()\n",
    "    for name,model in models:\n",
    "        model.fit(X_train_1, y_train_1)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    blender = LinearRegression()\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "def pred_ensemble(models, blender, X_test_1):\n",
    "    meta_X = list()\n",
    "    for name,model in models:\n",
    "        y_pred = model.predict(X_test_1)\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    return blender.predict(meta_X)\n",
    "\n",
    "models = get_models()\n",
    "blender = fit_ensemble(models, X_train_1, X_val, y_train_1, y_val)\n",
    "y_pred = pred_ensemble(models, blender, X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5e85aea-683f-4631-9222-1fec3f3df2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score\n",
      "xxxxxxxxxxxxxxxxxxxx\n",
      "MSE 0.023238055526779017\n",
      "Logistic regression: 0.10995299517654025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy score\")\n",
    "print(\"xxxxxxxxxxxxxxxxxxxx\")\n",
    "print(\"MSE\",(mean_squared_error(y_test_1,y_pred)))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_1, y_train_1)\n",
    "y_pred1= model.predict(X_test_1)\n",
    "print(\"Logistic regression:\",(mean_squared_error(y_test_1,y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923c8f8b-2c57-4b8e-afac-6c9a3043156f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
