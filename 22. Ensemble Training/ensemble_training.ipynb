{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8a9271-6e74-4205-a8fb-22ef54a45ea3",
   "metadata": {},
   "source": [
    "# Ensemble learning\n",
    "We will implement scratch implementation of three types of ensemble learning. Then check each effect on a smaller dataset.\n",
    "\n",
    "* Blending\n",
    "* Bagging\n",
    "* Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e105c265-7ce3-466e-b721-455451177a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c2a05d-854f-4b39-bdcf-214cc53a119f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  OpenPorchSF  \\\n",
       "0          2003       196.0         706  ...           0           61   \n",
       "1          1976         0.0         978  ...         298            0   \n",
       "2          2002       162.0         486  ...           0           42   \n",
       "3          1970         0.0         216  ...           0           35   \n",
       "4          2000       350.0         655  ...         192           84   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       2    2008   \n",
       "1              0          0            0         0        0       5    2007   \n",
       "2              0          0            0         0        0       9    2008   \n",
       "3            272          0            0         0        0       2    2006   \n",
       "4              0          0            0         0        0      12    2008   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train.csv').select_dtypes(include='number')\n",
    "data.isnull().sum()\n",
    "data = data.fillna(data.mean())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbc06b6-c912-45da-a6f2-ccdf6b991a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-(1460, 37), y-(1460,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['SalePrice'],axis=1).values\n",
    "y = data['SalePrice'].values\n",
    "X = np.log1p(X)\n",
    "y = np.log1p(y)\n",
    "print('X-{}, y-{}'.format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f09ed-341a-4a95-89db-9a5040dcc160",
   "metadata": {},
   "source": [
    "# Problem 1] Blending scratch mounting\n",
    "Show at least three​ ​examples of scratch implementation of blending that are more accurate than a single model. Higher accuracy means less mean squared error (MSE) on the validation data.\n",
    "\n",
    "# What is blending?\n",
    "Blending is a method of independently training N diverse models, weighting the estimation results, and then adding them together. The simplest is to take the average. Various models are created by changing the following conditions.\n",
    "\n",
    "Techniques (eg linear regression, SVM, decision tree, neural network, etc.)\n",
    "Hyperparameters (eg SVM kernel type, initial weights, etc.)\n",
    "How to preprocess input data (eg standardization, logarithmic transformation, PCA, etc.)\n",
    "The important thing is that each model is very different.\n",
    "\n",
    "Blending in regression problems is so simple that it is not provided in scikit-learn.\n",
    "\n",
    "《 Supplemental information\n",
    "》\n",
    "\n",
    "In the case of a classification problem, a majority vote will be taken. Because it is more complicated than regression problems, scikit-learn provides a Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce833ed0-85b3-469e-a381-91d6b33b8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82c523-83e7-47cb-8edd-698d084b7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions = list()\n",
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions.append(model.predict(X_test))\n",
    "    \n",
    "predictions_ndarray = np.array(predictions)\n",
    "blend = np.mean(predictions_ndarray,axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('Blend:{:.3f}'.format(mean_squared_error(y_test,blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dad69e-5fd4-4da8-b1de-7eaa51ca8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model1 = SVR(C=1)\n",
    "svr_model2 = SVR(C=5)\n",
    "svr_model3 = SVR(C=10)\n",
    "svr_model1.fit(X_train,y_train)\n",
    "svr_model2.fit(X_train,y_train)\n",
    "svr_model3.fit(X_train,y_train)\n",
    "svr_pred1 = svr_model1.predict(X_test)\n",
    "svr_pred2 = svr_model2.predict(X_test)\n",
    "svr_pred3 = svr_model2.predict(X_test)  \n",
    "svr_blend = np.mean([svr_pred1,svr_pred2,svr_pred3],axis=0)\n",
    "print('MSE')\n",
    "print('Blend:{:.3f}'.format(mean_squared_error(y_test,svr_blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4ce13-79ee-46bf-968c-bd339b36a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_trans = std_scaler.transform(X_train)\n",
    "X_test_trans = std_scaler.transform(X_test)\n",
    "\n",
    "models2 = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions2 = list()\n",
    "for model in models2:\n",
    "    model.fit(X_train_trans,y_train)\n",
    "    predictions2.append(model.predict(X_test_trans))\n",
    "    \n",
    "predictions_ndarray2 = np.array(predictions)\n",
    "blend2 = np.mean(predictions_ndarray2,axis=0)\n",
    "print('MSE')\n",
    "print('Blend:{:.3f}'.format(mean_squared_error(y_test,blend2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cb888-c0ea-4b26-98d0-b5a3b77a3d8d",
   "metadata": {},
   "source": [
    "# 4.Bagging\n",
    "# [Problem 2] Scratch mounting of bagging\n",
    "Please show at least one​ ​example where you scratch-implement the bagging and it is more accurate than a single model.\n",
    "\n",
    "# What is bagging?\n",
    "Bagging is a way to diversify how to select input data. N types of subsets (bootstrap samples) are created by randomly extracting from the training data after allowing duplication. N models are trained by them and the estimation results are averaged. Unlike blending, each weight does not change.\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "The part that averages the estimation results is implemented in the same way as blending.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c7271-973c-4149-93e3-f2f37da88d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train_bag.shape,y_test_bag.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1f72e-41da-48db-9a6b-e0b87949b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "class BaggingScratch():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.predictions = list()\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        for model in models:\n",
    "            model.fit(X,y)\n",
    "    def predict(self,X):\n",
    "        predictions = list()\n",
    "        for model in self.models:\n",
    "            prediction = model.predict(X)\n",
    "            predictions.append(prediction)\n",
    "        self.predictions = np.mean(np.array(predictions),axis=0)\n",
    "        return self.predictions\n",
    "    def mse(self, y):\n",
    "        mse = (mean_squared_error(y,self.predictions))\n",
    "        return mse\n",
    "    \n",
    "bag = BaggingScratch(models)\n",
    "bag.fit(X_train,y_train)\n",
    "print(\"average of bagging pred:{}\".format(bag.predict(X_test)))\n",
    "print(\"average of bagging mse:{:.3f}\".format(bag.mse(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b017c-934d-4a9b-b41e-efe33a6c8690",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "# [Problem 3] Stacking scratch mounting\n",
    "Please show at least one​ ​example where stacking is scratch-implemented and more accurate than a single model.\n",
    "\n",
    "What is stacking?\n",
    "The stacking procedure is as follows. Stacking is possible if there is at least stage 0 and stage 1, so implement it. First of all, we will start to the extent ​K​ ​0​ ​=​ ​3​,​ ​M​ ​0​ ​=​ ​2K0=3,M0=2.\n",
    "\n",
    "《When learning》\n",
    "\n",
    "(stage 00 ）\n",
    "\n",
    "Training data K​ ​0K0Divide into pieces.\n",
    "With(K​ ​0​ ​−​ ​1)(K0−1)Training data collectively, the rest 11for estimation, we can make K​ ​0K0 estimation.\n",
    "We haveK​ ​0K0Prepare individual pieces and learn using different training data.\n",
    "For each trained model, the remaining 11 unused estimation data is input to obtain an estimate. (This is called blended data.)\n",
    "We also prepare K​ ​0K0 instances of different models and do the same thing. If there are M​ ​0M0 models, M​ ​0M0 blended data will be obtained.\n",
    "(stage nn ）\n",
    "\n",
    "The blended data of stage n​ ​−​ ​1n−1 is considered as the training data with M​ ​n​ ​−​ ​1Mn−1Think of it as training data with dimensional features, K​ ​nKn pieces. The same applies below.\n",
    "(stage NN) *Last stage\n",
    "\n",
    "stage N​ ​−​ ​1N−1of M​ ​N​ ​−​ ​1MN−1Blend data M​ ​N​ ​−​ ​1MN−1One type of model is trained as an input of dimensional features. This is the model for the final estimation.\n",
    "《Estimated time》\n",
    "\n",
    "(stage 00 ）\n",
    "\n",
    "Test data K​ ​0​ ​x​ ​M​ ​0K0×M0Fill in the trained models and K​ ​0​ ​x​ ​M​ ​0K0×M0Get an estimate. this K​ ​0K0Calculate the average value on the axis of M​ ​0M0Obtain data with dimensional features. (Called a blend test)\n",
    "(stage nn ）\n",
    "\n",
    "The blended data of stage n​ ​−​ ​1n−1The blend test obtained in K​ ​n​ ​×​ ​M​ ​nKn×MnFill in the trained models and K​ ​n​ ​×​ ​M​ ​nKn×MnGet an estimate. this K​ ​nKnCalculate the average value on the axis of M​ ​0M0Obtain data with dimensional features. (Called a blend test)\n",
    "(stage NN) *Last stage\n",
    "\n",
    "stage N​ ​−​ ​1N−1Input the blend test obtained in step 2 into the trained model to obtain an estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffbeab6-e8f6-48ef-8ca3-6c03dd033018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    X, y = datasets.make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset()\n",
    "X_train_full, X_test_1, y_train_full, y_test_1 = train_test_split(X,y,test_size=0.5,random_state=1)\n",
    "\n",
    "# Splitting into train and validations(used for ensemble model)\n",
    "X_train_1, X_val, y_train_1, y_val = train_test_split(X_train_full,y_train_full,test_size=0.2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645b140-4582-422a-8bba-9290988aa2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to return the models in a form of a tuple\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr',LinearRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeRegressor()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "# a function to fit and blend all of our models\n",
    "def fit_ensemble(models, X_train_1, X_val, y_train_1, y_val):\n",
    "    # fit and predict using the validation data\n",
    "    \n",
    "    # a list to hold the predicted data from the base model for the blender model\n",
    "    meta_X = list()\n",
    "    \n",
    "    # loop through our models\n",
    "    for name,model in models:\n",
    "        model.fit(X_train_1, y_train_1)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # reshaping the predicted results into a matrix with one column\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    \n",
    "    # defining our blender\n",
    "    blender = LinearRegression()\n",
    "    \n",
    "    # fitting our blender using our meta values and y validation set\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "\n",
    "# a function to make predictions with our ensemble\n",
    "def pred_ensemble(models, blender, X_test_1):\n",
    "    # a list to hold te predictions for the blender\n",
    "    meta_X = list()\n",
    "    \n",
    "    # loop through our models\n",
    "    for name,model in models:\n",
    "        \n",
    "        # predicting using our base models\n",
    "        y_pred = model.predict(X_test_1)\n",
    "        \n",
    "        # reshaping the predicted results into a matrix with one column\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    \n",
    "    # predicting using our blender\n",
    "    return blender.predict(meta_X)\n",
    "\n",
    "models = get_models()\n",
    "blender = fit_ensemble(models, X_train_1, X_val, y_train_1, y_val)\n",
    "y_pred = pred_ensemble(models, blender, X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e85aea-683f-4631-9222-1fec3f3df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing mse\n",
    "print(\"Values used\")\n",
    "print(\"Train:{} Val:{} Test:{}\".format(X_train_1.shape, X_val.shape, X_test_1.shape))\n",
    "print(\"Accuracy score\")\n",
    "print(\"------------------\")\n",
    "print(\"Blended ensemble:{:.3f}\".format(mean_squared_error(y_test_1,y_pred)))\n",
    "\n",
    "# on individual model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_1, y_train_1)\n",
    "y_pred1= model.predict(X_test_1)\n",
    "print(\"Logistic regression:{:.3f}\".format(mean_squared_error(y_test_1,y_pred1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
