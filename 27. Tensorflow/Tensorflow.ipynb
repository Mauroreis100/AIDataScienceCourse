{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1: Looking back on scratch\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zzWNrxFJ53G6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look back at the previous scratches so far, To implement deep learning we:\n",
        "\n",
        "- Had to initialize the weights\n",
        "- Needed an epoch loop\n",
        "- Coded the Activation Functions\n",
        "- Decided the learning rate, sizes, number of nodes and so on"
      ],
      "metadata": {
        "id": "pXx9nxg93hRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 2: Consider the correspondence between scratch and TensorFlow\n",
        "We will use the Iris dataset that we have been using previously. The following sample code assumes thatIris.csvis in the same hierarchy.\n",
        "\n",
        "Iris Species\n",
        "\n",
        "The objective variable isSpecies, but only the following two types are used among the three types.\n",
        "\n",
        "Check the sample code below to see how TensorFlow implements the “things you need to implement deep learning” that we listed earlier.\n",
        "\n",
        "Please summarize it in simple words. It is not always a simple one-to-one correspondence.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_GOsRT04m2T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cNKvZovewj7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2385a782-eb60-4a12-b453-521693a9a775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss : 11.5137, val_loss : 8.0188, acc : 0.250, val_acc : 0.188\n",
            "Epoch 1, loss : 18.1036, val_loss : 9.4417, acc : 0.250, val_acc : 0.625\n",
            "Epoch 2, loss : 6.9596, val_loss : 5.7830, acc : 0.500, val_acc : 0.625\n",
            "Epoch 3, loss : 0.0271, val_loss : 2.8002, acc : 1.000, val_acc : 0.750\n",
            "Epoch 4, loss : 0.0000, val_loss : 2.2458, acc : 1.000, val_acc : 0.812\n",
            "Epoch 5, loss : 0.0000, val_loss : 1.8759, acc : 1.000, val_acc : 0.812\n",
            "Epoch 6, loss : 0.0000, val_loss : 2.3530, acc : 1.000, val_acc : 0.812\n",
            "Epoch 7, loss : 0.0000, val_loss : 1.1884, acc : 1.000, val_acc : 0.812\n",
            "Epoch 8, loss : 0.0000, val_loss : 1.4283, acc : 1.000, val_acc : 0.812\n",
            "Epoch 9, loss : 0.0000, val_loss : 0.9761, acc : 1.000, val_acc : 0.875\n",
            "test_acc : 0.850\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "dataset_path =\"Iris.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "\n",
        "y[y=='Iris-versicolor'] = 0\n",
        "y[y=='Iris-virginica'] = 1\n",
        "y = y.astype(int)[:, np.newaxis]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "def example_net(x):\n",
        "\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "\n",
        "logits = example_net(X)\n",
        "\n",
        "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above, we see that the Weights initialization is done through tf.Variable(tf.random_normal); Adam is used as an Optimizer and the activation function passes through tf.nn.relu."
      ],
      "metadata": {
        "id": "1kBPELtm5qLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 3: Create a model of Iris using all three types of objective variables\n",
        "\n",
        "There are a few other small datasets I’ve worked with so far. Please rewrite the above sample code and create a neural network that learns and estimates for these.\n",
        "\n",
        "Iris (using all three objective variables)\n",
        "House Prices\n",
        "Use all datasets in three types: train, val, and test.\n",
        "\n",
        "train.csv of the Iris dataset, create a model that can classify all three types contained in the objective variable Species.\n",
        "\n",
        "Iris Species\n",
        "\n",
        "Consider the difference between two-class classification and three or more classifications. Please refer to the official document etc. to find out how it can be rewritten by TensorFlow.\n",
        "\n",
        "« Hint »\n",
        "\n",
        "The following two places are processes specific to two-class classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "wR0dvh4M6PlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "dataset_path =\"Iris.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "\n",
        "y[y=='Iris-setosa'] = 0\n",
        "y[y=='Iris-versicolor'] = 1\n",
        "y[y=='Iris-virginica'] = 2\n",
        "y = y.astype(int)[:, np.newaxis]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train)\n",
        "y_val_one_hot = enc.transform(y_val)\n",
        "y_test_one_hot = enc.transform(y_test)\n",
        "\n",
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        # Convert sparse matrix to dense array if necessary\n",
        "        if hasattr(self.y, 'toarray'):\n",
        "            return self.X[p0:p1], self.y[p0:p1].toarray()\n",
        "        else:\n",
        "            return self.X[p0:p1], self.y[p0:p1]\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        # Convert sparse matrix to dense array if necessary\n",
        "        if hasattr(self.y, 'toarray'):\n",
        "            return self.X[p0:p1], self.y[p0:p1].toarray()\n",
        "        else:\n",
        "            return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 3\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train_one_hot, batch_size=batch_size)\n",
        "\n",
        "def example_net(x):\n",
        "\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "\n",
        "logits = example_net(X)\n",
        "\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(logits, 1))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val_one_hot})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test_one_hot})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKQRH9hW5q86",
        "outputId": "877bfd7f-7216-4064-9475-31a762bf12bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss : 7.3273, val_loss : 20.2655, acc : 0.833, val_acc : 0.625\n",
            "Epoch 1, loss : 0.0009, val_loss : 1.2011, acc : 1.000, val_acc : 0.875\n",
            "Epoch 2, loss : 2.8259, val_loss : 3.6142, acc : 0.667, val_acc : 0.875\n",
            "Epoch 3, loss : 1.2413, val_loss : 3.4787, acc : 0.833, val_acc : 0.875\n",
            "Epoch 4, loss : 0.0000, val_loss : 2.8319, acc : 1.000, val_acc : 0.833\n",
            "Epoch 5, loss : 0.0000, val_loss : 1.4375, acc : 1.000, val_acc : 0.958\n",
            "Epoch 6, loss : 0.8720, val_loss : 4.3355, acc : 0.833, val_acc : 0.875\n",
            "Epoch 7, loss : 0.0000, val_loss : 2.3592, acc : 1.000, val_acc : 0.833\n",
            "Epoch 8, loss : 0.0000, val_loss : 1.4582, acc : 1.000, val_acc : 0.958\n",
            "Epoch 9, loss : 1.1279, val_loss : 4.8429, acc : 0.833, val_acc : 0.875\n",
            "test_acc : 0.767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 4: Create a model of House Prices\n",
        "\n",
        "Create a model using House Prices, a data set for regression problems.\n",
        "\n",
        "House Prices: Advanced Regression Techniques\n",
        "\n",
        "Download thetrain.csv file and useSalePrice as the objective variable andGrLivArea and YearBuiltas explanatory variables. You can add more explanatory variables if you wish.\n",
        "\n",
        "Consider the difference between a classification problem and a regression problem.\n"
      ],
      "metadata": {
        "id": "lR2bDKIm8dMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "dataset_path =\"train.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "y = df[\"SalePrice\"]\n",
        "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "y = y.astype(int)[:, np.newaxis]\n",
        "y = np.log(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "def example_net(x):\n",
        "\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "\n",
        "logits = example_net(X)\n",
        "loss_op =  tf.losses.mean_squared_error(labels=Y, predictions=logits)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "y_pred = logits\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    loss_list = []\n",
        "    val_loss_list = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "        loss = sess.run(loss_op, feed_dict={X: X_train, Y: y_train})\n",
        "        loss_list.append(loss)\n",
        "        val_loss = sess.run(loss_op, feed_dict={X: X_val, Y: y_val})\n",
        "        val_loss_list.append(val_loss)\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}\".format(epoch, loss, val_loss))\n",
        "    print(\"test_mse : {:.3f}\".format(loss))\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.plot(loss_list, label='loss')\n",
        "    plt.plot(val_loss_list, label='val_loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "kVltCfHA8cgA",
        "outputId": "86ca2388-d682-474a-a483-bcc330759f05"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss : 674842.6250, val_loss : 520745.1875\n",
            "Epoch 1, loss : 119008.3438, val_loss : 111744.2734\n",
            "Epoch 2, loss : 104810.2422, val_loss : 116791.5312\n",
            "Epoch 3, loss : 81247.5469, val_loss : 96118.6562\n",
            "Epoch 4, loss : 62529.3828, val_loss : 76880.2656\n",
            "Epoch 5, loss : 51655.1641, val_loss : 63299.5312\n",
            "Epoch 6, loss : 45762.6328, val_loss : 54775.3477\n",
            "Epoch 7, loss : 37963.6602, val_loss : 44995.8477\n",
            "Epoch 8, loss : 27674.7383, val_loss : 32428.5586\n",
            "Epoch 9, loss : 20770.0293, val_loss : 23993.5742\n",
            "test_mse : 20770.029\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 5: Create a model of MNIST\n",
        "\n",
        "Create a model to classify the MNIST used in neural network scratches.\n",
        "\n",
        "It is similar to the previous Iris in that it is classified into 3 or more classes. The difference is that the input is an image.\n",
        "\n",
        "Aim to reproduce the model mounted by scratch.\n",
        "\n",
        "Check the GPU configuration status in tf.prueba.gpu_device_name() to see if it is recognized.\n",
        "\n",
        "Binar classification of Iris dataset using neural network implemented in TensorFlow\n",
        "\n",
        "Check the GPU configuration status with tf.test.gpu_device_name() to see if it is recognized.\n",
        "\n",
        "If successful, a log is output; if not recognized, nothing is output\n",
        "\n",
        "Install the GPU with “!pip install tensorflow-gpu==1.14.0”.\n",
        "\n",
        "to check the GPU setting status and see if it is recognized.\n",
        "\n",
        "Don’t forget when you change the version of tensorflow to the 1.x series.\n",
        "\n",
        "The following forms of ndarray, shape (n_samples, n_features)\n",
        "\n",
        "The following form of ndarray, shape (n_samples, 1)\n",
        "\n",
        "#Determine the shape of the argument to be passed to the calculation graph\n",
        "\n",
        "Simple 3-layer neural network\n",
        "\n",
        "Iterator to get a mini-batch\n",
        "\n",
        "#Read network structure\n",
        "\n",
        "#Condition extraction from data frame\n",
        "\n",
        "#Load dataset\n",
        "\n",
        "#Loop for each epoch\n",
        "\n",
        "#Declaration of weights and biases\n",
        "\n",
        "Further split into train and val\n",
        "\n",
        "NumPy random seed\n",
        "\n",
        "#Convert labels to numbers\n",
        "\n",
        "tf.add and + are equivalent\n",
        "\n",
        "#Run calculation graph\n",
        "\n",
        "Convert to NumPy array\n",
        "\n",
        "Initialization of #variable\n",
        "\n",
        "#Split into train and test\n",
        "\n",
        "#Indicator value calculation\n",
        "\n",
        "#Optimization method\n",
        "\n",
        "Batch size\n",
        "\n",
        "Training data\n",
        "\n",
        "Correct answer value"
      ],
      "metadata": {
        "id": "EecKPd-WEyTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "X_train = X_train.astype(np.float64)\n",
        "X_test = X_test.astype(np.float64)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "y_train = y_train.astype(int)[:, np.newaxis]\n",
        "y_test = y_test.astype(int)[:, np.newaxis]\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:])\n",
        "y_test_one_hot = enc.fit_transform(y_test[:])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
        "\n",
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 10\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "def example_net(x):\n",
        "\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "\n",
        "logits = example_net(X)\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "max_Y = (tf.argmax(Y, 1))\n",
        "max_Y_pred = tf.argmax(logits, 1)\n",
        "correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(logits, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test_one_hot})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynuAfEonE3Kh",
        "outputId": "060eb33a-10f1-4577-d5a6-20e74a46591d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 0, loss : 1.5837, val_loss : 1.2024, acc : 0.600, val_acc : 0.641\n",
            "Epoch 1, loss : 2.6681, val_loss : 0.8905, acc : 0.600, val_acc : 0.760\n",
            "Epoch 2, loss : 0.9247, val_loss : 0.7062, acc : 0.700, val_acc : 0.854\n",
            "Epoch 3, loss : 0.7721, val_loss : 0.5145, acc : 0.700, val_acc : 0.893\n",
            "Epoch 4, loss : 0.5646, val_loss : 0.3980, acc : 0.800, val_acc : 0.906\n",
            "Epoch 5, loss : 0.7615, val_loss : 0.3755, acc : 0.600, val_acc : 0.907\n",
            "Epoch 6, loss : 0.4409, val_loss : 0.3042, acc : 0.900, val_acc : 0.923\n",
            "Epoch 7, loss : 1.0057, val_loss : 0.3206, acc : 0.600, val_acc : 0.921\n",
            "Epoch 8, loss : 0.4320, val_loss : 0.3135, acc : 0.900, val_acc : 0.923\n",
            "Epoch 9, loss : 0.5413, val_loss : 0.4098, acc : 0.800, val_acc : 0.926\n",
            "test_acc : 0.925\n"
          ]
        }
      ]
    }
  ]
}